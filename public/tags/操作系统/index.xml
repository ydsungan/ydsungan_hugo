<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>操作系统 on ydsungan的博客</title>
        <link>http://ydsungan.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</link>
        <description>Recent content in 操作系统 on ydsungan的博客</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Wed, 30 Mar 2022 14:47:12 +0800</lastBuildDate><atom:link href="http://ydsungan.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>内存管理</title>
        <link>http://ydsungan.com/p/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</link>
        <pubDate>Wed, 30 Mar 2022 14:47:12 +0800</pubDate>
        
        <guid>http://ydsungan.com/p/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</guid>
        <description>&lt;h1 id=&#34;1-虚拟内存&#34;&gt;1 虚拟内存&lt;/h1&gt;
&lt;p&gt;​		内存是计算机系统的重要计算资源。在介绍具体的内存管理机制之前，先思考这个问题：当多个应用程序同时运行时，操作系统该如何让它们共同使用物理内存资源呢?&lt;/p&gt;
&lt;p&gt;​		一种简单的方法是：当一个应用程序 A 运行时，允许它访问所有的物理内存资源；在切换到另一个应用程序 B 运行的过程中，操作系统将应用程序 A 的所有内存数据保存到存储设备（如磁盘）中，然后将应用程序 B 的数据从存储设备加载到内存中。但是这种方法存在明显的弊端：由于读写存储设备的速度很慢，这将导致切换程序的时间开销太大。&lt;/p&gt;
&lt;p&gt;​		另—种简单的方法是：让每个应用程序独立使用物理内存的—部分，数据—直驻留在内存中，在程序切换时不再需要操作存储设备。该方法在性能方面优于前一种方法，但是也存在两个严重的弊端：第—，无法保证不同应用程序所使用的物理内存之间的隔离性，比如应用程序 A 在运行过程中可能意外地写了应用程序B的物理内存，进而导致后者错误运行；第二，无法保证应用程序可用的地址空间是连续的和统一的，增加了程序编写及编译的复杂性。&lt;/p&gt;
&lt;p&gt;​		操作系统究竟是如何让不同的应用程序能够既高效又安全地共同使用物理内存资源的？现代操作系统的一个普遍做法是在应用程序与物理内存之间加入一个新的抽象：&lt;strong&gt;虚拟内存&lt;/strong&gt;（virtual memory）。&lt;strong&gt;应用程序是面向虚拟内存编写的&lt;/strong&gt;，而不再是面向物理内存编写的；应用程序在运行时只能使用虚拟地址，CPU负责将虚拟地址翻译成物理地址，操作系统负责设置虚拟地址与物理地址之间的映射。操作系统仅将应用程序实际使用的虚拟地址映射到物理地址，从而提高内存资源的利用率；每个应用程序只能看到自己的虚拟地址空间。从而保证不同应用程序所用内存之间的隔离：每个应用程序的虚拟地址空间是统一的、连续的，从而降低了编程的复杂性。&lt;/p&gt;
&lt;h1 id=&#34;2-物理地址和虚拟地址&#34;&gt;2 物理地址和虚拟地址&lt;/h1&gt;
&lt;p&gt;​		逻辑上，可以把物理内存看成一个大数组，其中每个字节都可以通过与之唯—对应的地址进行访问，这个地址就是&lt;strong&gt;物理地址&lt;/strong&gt;（physical address）。在应用程序或操作系统运行过程中，CPU通过总线发送访问物理地址的请求，从内存中读取数据或者向其中写人数据。&lt;/p&gt;
&lt;p&gt;​		在引人虚拟内存的抽象后应用程序使用&lt;strong&gt;虚拟地址&lt;/strong&gt;（virtual address）访问存储在内存中的数据和代码。在程序扶行过程中，CPU会把虚拟地址转换成物理地址，然后通过后者访问物理内存。虚拟地址转换成物理地址的过程，通常被称为&lt;strong&gt;地址翻译&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;21-使用虚拟地址访问内存单元&#34;&gt;2.1 使用虚拟地址访问内存单元&lt;/h2&gt;
&lt;p&gt;​		CPU中的重要部件，&lt;strong&gt;内存管理单元&lt;/strong&gt;（Memory Management Unit，&lt;strong&gt;MMU&lt;/strong&gt;），负责虚拟地址到物理地址的转换。程序在CPU核心上运行期间，它使用的虚拟地址都会由 MMU 进行翻译。当需要访问物理内存设备的时候，MMU 翻译出的物理地址将会通过总线传到相应的物理内存设备，从而完成相应的物理内存读写请求。&lt;/p&gt;
&lt;p&gt;​		以运行Hello World 程序的第—条指令为例：操作系统首先把程序从磁盘／SSD 加载到物理内存中，然后让CPU去执行程序的第—条指令，但是此时该指令存在于内存中。在使用虚拟内存的情况下，CPU取指令时发出的是指令的虚拟地址，该虚拟地址被 MMU翻译为对应的物理地址，包含该物理地址的内存读请求被发送到物理内存设备，然后物理内存设备把该物理地址对应的内容（即Hello World程序的第一条指令）发送给 CPU。&lt;/p&gt;
&lt;p&gt;​		为了加速地址翻译的过程，现代CPU都引人了转址旁路缓存（Translation Lookaside Buffer，TLB）。TLB是属于MMU内部的单元。&lt;/p&gt;
&lt;h2 id=&#34;22-分段和分页机制&#34;&gt;2.2 分段和分页机制&lt;/h2&gt;
&lt;p&gt;​		MMU将虚拟地址翻译为物理地址的主要机制有两种：分段机制和分页机制。&lt;/p&gt;
&lt;p&gt;​		在分段机制下，不仅虚拟内存空间被划分成不同的段，物理内存也以段为单位进行分配。在虚拟地址空间中，相邻的段所对应的物理内存中的段可以不相邻，因此，操作系统能够实现物理内存资源的离散分配。分段容易导致外部碎片。例如：如果一共有 6GB 的物理内存，目前被划分成4 段进行分配，第—段为0～2GB，第二段为2～3GB，第三段为3～5GB，第四段为 5～6GB；如果第二段和第四段被释放，然后又需要分配—个2GB的段，虽然此时空闲的物理内存总量为2GB，但因为这2GB内存不连续，因此分配还是会失败。&lt;/p&gt;
&lt;p&gt;​		应用程序的虚拟地址空间由若干个&lt;strong&gt;不同大小的段&lt;/strong&gt;组成，比如代码段、数据段等。当 CPU访问虚拟地址空间中某一个段的时候，MMU 会通过查询&lt;strong&gt;段表&lt;/strong&gt;得到该段对应的物理内存区域。具体来说，虚拟地址由两部分构成：第—个部分表示段号，标识着该虚拟地址属于整个虚拟地址空间中的哪—个段；第二个部分表示段内地址，或称段内偏移，即相对于该段起始地址的偏移量。&lt;/p&gt;
&lt;p&gt;​		现代操作系统广泛采用的是分页机制。分页机制将应用程序的虚拟地址空间划分成&lt;strong&gt;连续的、等长的虚拟页&lt;/strong&gt;，不同于分段机制下大小不同的段。虚拟页和物理页的页长固定且相等。&lt;/p&gt;
&lt;p&gt;​		在分页机制下，应用程序虚拟地址空间中的任意虚拟页可以被映射到物理内存中的任意物理页上。因此操作系统也能实现物理内存资源的离散分配。分页机制按照固定页大小分配物理内存，使得物理内存资源易于管理可有效避免分段机制中外部碎片的问题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://ydsungan.com/post/memory_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;memory&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;23-虚拟内存的功能&#34;&gt;2.3 虚拟内存的功能&lt;/h2&gt;
&lt;p&gt;​		&lt;strong&gt;共享内存&lt;/strong&gt; (shared memory) 允许同—个物理页在不同的应用程序间共享，例如，应用程序 A 的虚拟页 V1 被映射到物理页P，若应用程序B的虚拟页 V2 也被映射到物理页P，则物理页 P 是应用程序 A 和应用程序 B 的共享内存。应用程序 A 读取虚拟页 V1 和应用程序 B 读取虚拟页 V2 将得到相同的内容，互相也能看到对方修改的内容。共享内存的一个基本用途是可以让不同的应用程序之间互相通信、传递数据。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://ydsungan.com/post/memory_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;memory2&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>页缓存、直接IO及内存映射</title>
        <link>http://ydsungan.com/p/%E9%A1%B5%E7%BC%93%E5%AD%98%E7%9B%B4%E6%8E%A5io%E5%8F%8A%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84/</link>
        <pubDate>Wed, 30 Mar 2022 14:30:12 +0800</pubDate>
        
        <guid>http://ydsungan.com/p/%E9%A1%B5%E7%BC%93%E5%AD%98%E7%9B%B4%E6%8E%A5io%E5%8F%8A%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84/</guid>
        <description>&lt;p&gt;​		对文件系统中结构的修改都是直接在存储设备中进行的。然而在存储设备上直接访问数据有两个问题。首先，目前大多数存储设备都是块接口，读写粒度为—个块，大小通常为 512B 或者 4KB。然而文件系统所进行的更改往往并非对齐到块的边界，其读写的字节数也并非恰好为块大小的整数倍。其次，存储设备的访问速度慢，与内存相比要慢几个数量级。大量频繁的存储设备访问操作会成为应用程序的性能瓶颈。&lt;/p&gt;
&lt;h2 id=&#34;1-访问粒度不一致问题和一些优化&#34;&gt;1 访问粒度不一致问题和一些优化&lt;/h2&gt;
&lt;p&gt;​		文件系统使用内存作为中转来解决访问粒度不—致的问题。假设一个存储设备的块大小为 4KB。当文件系统需要修改存储设备中的 8B 时，其需要先从存储设备中找到这8个字节所在的块号。通过块号，文件系统将整个块中的数据读入一个 4KB 大小的内存页之中。文件系统在内存页中修改这8个字节，并将修改后的内存页通过驱动写回到存储设备之中。这实际上是一个“读取—修改—写回”的过程。&lt;/p&gt;
&lt;p&gt;​		其中一个明显的问题是，若每个文件请求中每个结构的修改都经过完整的 “&lt;strong&gt;读取-修改-写回&lt;/strong&gt;” 过程，将会产生大量的磁盘访问。有一些比较简单的优化可以避免一些不必要的磁盘访问。&lt;/p&gt;
&lt;p&gt;​		之所以要在修改和写回之前先读取，是因为我们只想修改存储块下的一部分，而写回操作会覆盖整个存储块。为了保证此存储块中其他部分的数据不变，我们需要先将这些数据读出来，之后随修改后的数据一同写回到存储设备中。但是，如果一次修改的数据量刚好覆盖了整个存储块，那么就不用进行读取操作，可以直接将修改后的4096个字节写回到存储设备中。&lt;/p&gt;
&lt;p&gt;​		此外，如果一个文件请求中的多次修改均是在同—个存储块中，那么可以将多次修改合并到一个 “&lt;strong&gt;读取-修改-写回&lt;/strong&gt;” 的过程中，即变为 “&lt;strong&gt;读取-修改1-修改2-修改3-…修改n-写回&lt;/strong&gt;” 。这样，同样访问了两次存储设备，却完成了多次修改。&lt;/p&gt;
&lt;h2 id=&#34;2-读缓存&#34;&gt;2 读缓存&lt;/h2&gt;
&lt;p&gt;​		文件的访问具有时间局部性：当文件的一部分被访问后，有较高的概率其会再次被使用。因此，当文件系统从设备中读取了某个文件的数据之后，可以让这些数据继续保留在内存中一段时间。这样，当应用程序需要再次读取这些数据时，就可以从此前保留在内存中的数据中读取，从而避免了存储设备的访问。这便是文件系统中的读缓存。&lt;/p&gt;
&lt;p&gt;​		读缓存是需要占用内存空间的。为了防止该缓存占用过多的内存，澡作系统会对读缓存的大小进行限制。当读缓存占用过多内存时，使用 LRU 等策略回收读缓存占用的内存。&lt;/p&gt;
&lt;h2 id=&#34;3-写缓冲区和写合并&#34;&gt;3 写缓冲区和写合并&lt;/h2&gt;
&lt;p&gt;​		一般默认一个写请求结束之后，所有的写入数据均已被持久化到存储设备上，也就是说在文件写入请求完成后立刻发生断电和崩溃等情况，在系统恢复后，刚刚写入的文件数据依然能够被读取到。这是一个较强但十分合理的保证。然而由于存储设备的性能较差，若每个写请求均等待写入设备完成，文件写操作的延时变长，吞吐量会严重下降，从而影响整个系统的性能。&lt;/p&gt;
&lt;p&gt;​		为了获得更好的性能，在文件系统的设计中有一个权衡：在—个文件写请求返回到应用程序之后，允许其修改的数据暂时不持久化到存储设备中。这个权衡允许文件系统暂时将修改的数据保存在内存中，并在后台慢慢地持久化到存储设备上，然而这样却牺牲了—定的可靠性。在前面的例子中，如果在文件写请求完成后立刻发生断电，再次开机之后，刚刚完成写入的数据可能会丢失。为了确保数据被持久化到设备中，POSIX 中规定了 &lt;strong&gt;fsync&lt;/strong&gt; 接口，用于保证某个已打开文件的所有修改全部被持久化到存储设备中。&lt;/p&gt;
&lt;p&gt;​		当文件系统修改完文件数据后，其修改会被暂存在写缓冲区的内存页之中。如果后续的文件请求需要读取或者修改相同存储块中的数据，文件系统可以直接在写缓冲区对应的内存页上进行读取或者修改。当可用内存不足，或者对应的 &lt;strong&gt;fsync&lt;/strong&gt; 被调用时，写缓冲区内存页中的数据才写回到存储设备对应的存储块之中。这样，一段时间内同一个存储块上的多个写请求可以合并一个磁盘写操作。&lt;/p&gt;
&lt;h2 id=&#34;4-页缓存&#34;&gt;4 页缓存&lt;/h2&gt;
&lt;p&gt;​		在Linux内核中，读缓存与写缓冲区的功能被合并起来管理，称为页缓存。页缓存以内存页为单位，将存储设备中的存储位置映射到内存中。文件系统通过调用 VFS 提供的相应接口对页缓存进行操作。&lt;/p&gt;
&lt;p&gt;​		当—个文件被读取时，文件系统会先检查其内容是否已经保存在页缓存中。如果文件数据已保存在页缓存中，则文件系统直接从页缓存中读取数据返回给应用程序；否则，文件系统会在页缓存中创建新的内存页，并从存储设备中读取相关的数据然后将其保存在创建的内存页中。之后，文件系统从内存页中读取相应的数据，返回给应用程序。&lt;/p&gt;
&lt;p&gt;​		在进行文件修改时，文件系统同样会首先检查页缓存。如果要修改的数据已经在页缓存中，文件系统可以直接修改页缓存中的数据，并将该页标记为脏页；若不在页缓存中，文件系统同样先创建页缓存并从存储没备中读取数据，然后在页缓存中进行修改并标记该页为脏页。标记为脏页的缓存会由文件系统定期写回到存储设备中。当操作系统内存不足或者应用程序调用 &lt;strong&gt;fsync&lt;/strong&gt; 时，文件系统也会将脏页中的数据写回到存储设备中。&lt;/p&gt;
&lt;h2 id=&#34;5-直接io&#34;&gt;5 直接IO&lt;/h2&gt;
&lt;p&gt;​		&lt;strong&gt;直接IO&lt;/strong&gt;就是不需要读缓冲，不需要写缓冲区和写合并。&lt;/p&gt;
&lt;p&gt;​		页缓存是持久化和性能之间权衡的产物。在大多数情况下，页缓存能够显著地提升文件系统性能。然而并非在所有情况下页缓存都能起到正面作用。一方面，部分应用对数据持久化有较强的要求，不希望文件的修改内容缓存在页缓存中。如果使用页缓存的机制，这些应用需要在每次修改文件后立即执行 &lt;strong&gt;fsync&lt;/strong&gt; 操作进行同步，这会影响应用程序的性能。另一方面，一些应用程序（如数据库等）会自己实现缓存机制对数据进行缓存和管理。由于应用程序更加了解自己对数据的需求,在这种情况下，操作系统提供的页缓存机制是冗余的，且一般会带来额外的性能开销。&lt;/p&gt;
&lt;p&gt;​		因此，文件系统将是否使用页缓存的判断和选择权交给了应用程序。应用程序可以在打开文件时通过附带 &lt;strong&gt;O_DIRECT&lt;/strong&gt; 标志，提示文件系统不要使用页缓存。这种文件访问方式就是&lt;strong&gt;直接 I/O&lt;/strong&gt; 。而相对应地，使用页缓存的文件请求称为缓存I/O。&lt;/p&gt;
&lt;h2 id=&#34;6-内存映射&#34;&gt;6 内存映射&lt;/h2&gt;
&lt;p&gt;​		除了文件的 read 和 write 接口外，应用程序还可以通过内存映射机制，以访问内存的形式访问文件内容。Linux在其页缓存的基础上实现了文件的内存映射机制。&lt;/p&gt;
&lt;p&gt;​		将一个文件或者其它对象映射到进程虚拟地址空间，实现文件磁盘地址和进程虚拟地址空间中的地址一一对映关系。&lt;/p&gt;
&lt;p&gt;​		&lt;img src=&#34;http://ydsungan.com/post/mmap_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;内存映射&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;7-页缓存与内存映射的区别&#34;&gt;7 页缓存与内存映射的区别&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;页缓存IO中数据从块设备到页缓存，再到用户缓冲区，经过俩次拷贝；而 mmap 方式下，当发生缺页中断时才去磁盘拷贝，然后直接对内存读写。&lt;/li&gt;
&lt;li&gt;处理大文件时，页缓存IO方式使用 read/write 系统调用一块一块的双份拷贝，而 mmap 方式把文件映射到虚拟地址空间，可以让磁盘空间替代内存。&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        
    </channel>
</rss>
